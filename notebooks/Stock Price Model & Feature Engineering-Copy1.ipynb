{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import datetime\n",
    "from matplotlib import style\n",
    "style.use('ggplot')\n",
    "import math\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:/Users/Olatomiwa/Documents/SOL PLAATJE UNIVERSITY/HONOURS 2019/RESEARCH/From Supervisor Dr Mosia/first_yahoo_prices_volumes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adj Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-09-10</td>\n",
       "      <td>19.680000</td>\n",
       "      <td>19.430000</td>\n",
       "      <td>19.650000</td>\n",
       "      <td>19.610001</td>\n",
       "      <td>4309400.0</td>\n",
       "      <td>18.881136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-09-11</td>\n",
       "      <td>19.540001</td>\n",
       "      <td>19.200001</td>\n",
       "      <td>19.469999</td>\n",
       "      <td>19.410000</td>\n",
       "      <td>6268000.0</td>\n",
       "      <td>18.688570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-09-12</td>\n",
       "      <td>19.530001</td>\n",
       "      <td>19.100000</td>\n",
       "      <td>19.530001</td>\n",
       "      <td>19.120001</td>\n",
       "      <td>6563400.0</td>\n",
       "      <td>18.409348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-09-15</td>\n",
       "      <td>19.209999</td>\n",
       "      <td>18.780001</td>\n",
       "      <td>19.180000</td>\n",
       "      <td>18.860001</td>\n",
       "      <td>7353800.0</td>\n",
       "      <td>18.159008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-09-16</td>\n",
       "      <td>19.240000</td>\n",
       "      <td>18.750000</td>\n",
       "      <td>18.809999</td>\n",
       "      <td>19.139999</td>\n",
       "      <td>5498400.0</td>\n",
       "      <td>18.428604</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date       High        Low       Open      Close     Volume  \\\n",
       "0  2014-09-10  19.680000  19.430000  19.650000  19.610001  4309400.0   \n",
       "1  2014-09-11  19.540001  19.200001  19.469999  19.410000  6268000.0   \n",
       "2  2014-09-12  19.530001  19.100000  19.530001  19.120001  6563400.0   \n",
       "3  2014-09-15  19.209999  18.780001  19.180000  18.860001  7353800.0   \n",
       "4  2014-09-16  19.240000  18.750000  18.809999  19.139999  5498400.0   \n",
       "\n",
       "   Adj Close  \n",
       "0  18.881136  \n",
       "1  18.688570  \n",
       "2  18.409348  \n",
       "3  18.159008  \n",
       "4  18.428604  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Checking the change after 7 dqys\n",
    "+ Lag the data for past 7 days\n",
    "+ Compare and map the target values\n",
    "+ 1 = Gain; 0 = Fall;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gain_fall(*args): # *args lets us pass any parameters, any number of arguments which becomes an iterable\n",
    "    cols = [c for c in args] # passing each column mapping it row wise\n",
    "    for col in cols:\n",
    "        if(col > 0):\n",
    "            return(1)   # GAIN\n",
    "        if(col < 0):\n",
    "            return(0)# FALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>1day_Lag</th>\n",
       "      <th>1day_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-09-10</td>\n",
       "      <td>19.680000</td>\n",
       "      <td>19.430000</td>\n",
       "      <td>19.650000</td>\n",
       "      <td>19.610001</td>\n",
       "      <td>4309400.0</td>\n",
       "      <td>18.881136</td>\n",
       "      <td>-0.010199</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-09-11</td>\n",
       "      <td>19.540001</td>\n",
       "      <td>19.200001</td>\n",
       "      <td>19.469999</td>\n",
       "      <td>19.410000</td>\n",
       "      <td>6268000.0</td>\n",
       "      <td>18.688570</td>\n",
       "      <td>-0.014941</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-09-12</td>\n",
       "      <td>19.530001</td>\n",
       "      <td>19.100000</td>\n",
       "      <td>19.530001</td>\n",
       "      <td>19.120001</td>\n",
       "      <td>6563400.0</td>\n",
       "      <td>18.409348</td>\n",
       "      <td>-0.013598</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-09-15</td>\n",
       "      <td>19.209999</td>\n",
       "      <td>18.780001</td>\n",
       "      <td>19.180000</td>\n",
       "      <td>18.860001</td>\n",
       "      <td>7353800.0</td>\n",
       "      <td>18.159008</td>\n",
       "      <td>0.014846</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-09-16</td>\n",
       "      <td>19.240000</td>\n",
       "      <td>18.750000</td>\n",
       "      <td>18.809999</td>\n",
       "      <td>19.139999</td>\n",
       "      <td>5498400.0</td>\n",
       "      <td>18.428604</td>\n",
       "      <td>0.000523</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date       High        Low       Open      Close     Volume  \\\n",
       "0  2014-09-10  19.680000  19.430000  19.650000  19.610001  4309400.0   \n",
       "1  2014-09-11  19.540001  19.200001  19.469999  19.410000  6268000.0   \n",
       "2  2014-09-12  19.530001  19.100000  19.530001  19.120001  6563400.0   \n",
       "3  2014-09-15  19.209999  18.780001  19.180000  18.860001  7353800.0   \n",
       "4  2014-09-16  19.240000  18.750000  18.809999  19.139999  5498400.0   \n",
       "\n",
       "   Adj Close  1day_Lag  1day_target  \n",
       "0  18.881136 -0.010199          0.0  \n",
       "1  18.688570 -0.014941          0.0  \n",
       "2  18.409348 -0.013598          0.0  \n",
       "3  18.159008  0.014846          1.0  \n",
       "4  18.428604  0.000523          1.0  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['1day_Lag'] = (df['Adj Close'].shift(-1) - df['Adj Close']) / df['Adj Close']\n",
    "# .shift shifts up to get the future value old - new divided by \n",
    "        \n",
    "df['1day_target'] = list(map(gain_fall, *[df['1day_Lag']]))\n",
    "\n",
    "df['1day_target'] = df['1day_target'].shift(1)\n",
    "df['1day_target'].fillna(0, inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['1day_target'] = df['1day_target'].shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    NaN\n",
       "1    0.0\n",
       "2    0.0\n",
       "3    0.0\n",
       "4    1.0\n",
       "Name: 1day_target, dtype: float64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['1day_target'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.0\n",
       "1    0.0\n",
       "2    0.0\n",
       "3    0.0\n",
       "4    1.0\n",
       "Name: 1day_target, dtype: float64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['1day_target'].fillna(0, inplace = True)\n",
    "df['1day_target'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data spread:  Counter({'1.0': 584, '0.0': 497})\n"
     ]
    }
   ],
   "source": [
    "# The distribution of the 1day_target mapping\n",
    "vals = df['1day_target'].values #.tolist optional \n",
    "str_vals = [str(i) for i in vals]\n",
    "\n",
    "print('Data spread: ', Counter(str_vals)) # seeing th way in which buys/sell/hold are distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCBHlJNALIUSUk0AvhBBR7v8D7EJ2+70yKGkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['Adj Close'].plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return of Adj price (Normalised by one day)\n",
    "df_return = df['Adj Close'].pct_change()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_return = df_return.replace([np.inf, -np.inf], np.nan) # replacing infinite changes with nan\n",
    "df_return.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAD8CAYAAACfF6SlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n5+oAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_return.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "days = 7 # Number of days\n",
    "for i in range(1, days + 1):\n",
    "    #### Company name and days into the future\n",
    "    df['{}day_Lag'.format(i)] = (df['Adj Close'].shift(-i) - df['Adj Close']) / df['Adj Close']\n",
    "    #### .shift shifts up to get the future value old - new divided by \n",
    "        \n",
    "    df['{}day_target'.format(i)] = list(map(gain_fall, *[df['{}day_Lag'.format(i)]for i in range(1, days+1)]))\n",
    "    \n",
    "df.fillna(0, inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'x_features': df['Adj Close'].pct_change(),\n",
    "                     'y_target': df['1day_target']}\n",
    "frame = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_features</th>\n",
       "      <th>y_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.010199</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.014941</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.013598</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.014846</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000523</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   x_features  y_target\n",
       "1   -0.010199       0.0\n",
       "2   -0.014941       0.0\n",
       "3   -0.013598       0.0\n",
       "4    0.014846       1.0\n",
       "5    0.000523       1.0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Net (Deep) 2 hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import LSTM\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using train_test_fit to create subsets for fitting and testing\n",
    "x_train, x_test, y_train, y_test = train_test_split(frame['x_features'], frame['y_target'], test_size = 0.3, random_state = 23, stratify = frame['y_target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    # Flattening the input Layer into a vector because it is a matrix\n",
    "    Flatten(),\n",
    "    \n",
    "    #First hidden layer \n",
    "    Dense(256, activation = 'relu'), # or tf.nn.relu\n",
    "    \n",
    "    #to prevent overfitting\n",
    "    Dropout(0.20),\n",
    "    \n",
    "    Dense(128, activation = 'relu'),\n",
    "    \n",
    "    Dropout(0.20),\n",
    "    \n",
    "    #output layer with 1 neuron with the sigmoid function to counter for the 2 classes (1 or 0)\n",
    "    Dense(1, activation = 'sigmoid') # or tf.nn.softmax\n",
    "       \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compiler; using the adam optimizer and binary_crossentropy for binary classification\n",
    "model.compile(optimizer='adam', loss = 'binary_crossentropy', metrics = ['accuracy'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "756/756 [==============================] - 2s 2ms/sample - loss: 0.6749 - acc: 0.7698\n",
      "Epoch 2/20\n",
      "756/756 [==============================] - 0s 173us/sample - loss: 0.6270 - acc: 0.7857\n",
      "Epoch 3/20\n",
      "756/756 [==============================] - 0s 175us/sample - loss: 0.5590 - acc: 0.8347\n",
      "Epoch 4/20\n",
      "756/756 [==============================] - 0s 147us/sample - loss: 0.4738 - acc: 0.8717\n",
      "Epoch 5/20\n",
      "756/756 [==============================] - 0s 168us/sample - loss: 0.4023 - acc: 0.8810\n",
      "Epoch 6/20\n",
      "756/756 [==============================] - 0s 124us/sample - loss: 0.3225 - acc: 0.9206\n",
      "Epoch 7/20\n",
      "756/756 [==============================] - 0s 136us/sample - loss: 0.2795 - acc: 0.9220\n",
      "Epoch 8/20\n",
      "756/756 [==============================] - 0s 215us/sample - loss: 0.2316 - acc: 0.9511\n",
      "Epoch 9/20\n",
      "756/756 [==============================] - 0s 122us/sample - loss: 0.2075 - acc: 0.9299\n",
      "Epoch 10/20\n",
      "756/756 [==============================] - 0s 208us/sample - loss: 0.1840 - acc: 0.9669\n",
      "Epoch 11/20\n",
      "756/756 [==============================] - 0s 171us/sample - loss: 0.1611 - acc: 0.9537\n",
      "Epoch 12/20\n",
      "756/756 [==============================] - 0s 136us/sample - loss: 0.1535 - acc: 0.9524\n",
      "Epoch 13/20\n",
      "756/756 [==============================] - 0s 157us/sample - loss: 0.1695 - acc: 0.9220\n",
      "Epoch 14/20\n",
      "756/756 [==============================] - 0s 132us/sample - loss: 0.1387 - acc: 0.9444\n",
      "Epoch 15/20\n",
      "756/756 [==============================] - 0s 130us/sample - loss: 0.1168 - acc: 0.9722\n",
      "Epoch 16/20\n",
      "756/756 [==============================] - 0s 147us/sample - loss: 0.1097 - acc: 0.9735\n",
      "Epoch 17/20\n",
      "756/756 [==============================] - 0s 110us/sample - loss: 0.1031 - acc: 0.9788\n",
      "Epoch 18/20\n",
      "756/756 [==============================] - 0s 131us/sample - loss: 0.1017 - acc: 0.9735\n",
      "Epoch 19/20\n",
      "756/756 [==============================] - 0s 116us/sample - loss: 0.0968 - acc: 0.9709\n",
      "Epoch 20/20\n",
      "756/756 [==============================] - 0s 132us/sample - loss: 0.0907 - acc: 0.9735\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x25d14ffdb00>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the data; 10 iterations\n",
    "model.fit(x_train.values, y_train.values, epochs = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "324/324 [==============================] - 0s 1ms/sample - loss: 0.0811 - acc: 0.9907\n",
      "\n",
      "Test Data Loss: 0.08108309812751817\n",
      "\n",
      "Test Data Accuracy: 99.074%\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the test dataset\n",
    "eval_array = model.evaluate(x_test, y_test)\n",
    "\n",
    "print(\"\\nTest Data Loss: {}\".format(eval_array[0]))\n",
    "print(\"\\nTest Data Accuracy: {:.5}%\".format(eval_array[1] * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas_ml import ConfusionMatrix as my_con"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.63973117e-01],\n",
       "       [8.35388899e-04],\n",
       "       [0.00000000e+00],\n",
       "       [5.95918298e-03],\n",
       "       [8.66903067e-01],\n",
       "       [9.92367864e-01],\n",
       "       [4.69177961e-04],\n",
       "       [6.13311410e-01],\n",
       "       [4.38392162e-05],\n",
       "       [9.25572813e-02],\n",
       "       [9.99992967e-01],\n",
       "       [9.99998391e-01],\n",
       "       [9.99125719e-01],\n",
       "       [2.73883343e-05],\n",
       "       [1.00000000e+00],\n",
       "       [1.21593475e-04],\n",
       "       [9.99943137e-01],\n",
       "       [6.42538071e-05],\n",
       "       [0.00000000e+00],\n",
       "       [0.00000000e+00],\n",
       "       [1.04928017e-03],\n",
       "       [9.99972820e-01],\n",
       "       [9.97770071e-01],\n",
       "       [9.99967337e-01],\n",
       "       [8.19057226e-04],\n",
       "       [9.99999225e-01],\n",
       "       [1.05217099e-03],\n",
       "       [3.57627869e-06],\n",
       "       [9.99987245e-01],\n",
       "       [7.46164620e-02],\n",
       "       [9.60549116e-01],\n",
       "       [3.42607498e-03],\n",
       "       [9.99992371e-01],\n",
       "       [9.99576390e-01],\n",
       "       [9.86895680e-01],\n",
       "       [9.12431002e-01],\n",
       "       [9.99996781e-01],\n",
       "       [8.71834159e-02],\n",
       "       [0.00000000e+00],\n",
       "       [8.16661417e-02],\n",
       "       [2.32944757e-01],\n",
       "       [1.23381615e-05],\n",
       "       [9.79781151e-04],\n",
       "       [9.99995172e-01],\n",
       "       [9.56726909e-01],\n",
       "       [1.00000000e+00],\n",
       "       [5.14307618e-03],\n",
       "       [1.00000000e+00],\n",
       "       [9.99987483e-01],\n",
       "       [9.99721289e-01],\n",
       "       [9.99959409e-01],\n",
       "       [9.99999404e-01],\n",
       "       [6.70880079e-04],\n",
       "       [9.99796391e-01],\n",
       "       [9.99984384e-01],\n",
       "       [5.28097153e-05],\n",
       "       [9.99985337e-01],\n",
       "       [9.99999225e-01],\n",
       "       [9.97844338e-01],\n",
       "       [8.59647989e-02],\n",
       "       [9.67115164e-04],\n",
       "       [3.18416953e-03],\n",
       "       [9.99971688e-01],\n",
       "       [1.00000000e+00],\n",
       "       [5.04297018e-03],\n",
       "       [8.58306885e-05],\n",
       "       [1.13159418e-04],\n",
       "       [9.34492230e-01],\n",
       "       [1.00000000e+00],\n",
       "       [2.04741955e-05],\n",
       "       [9.57746029e-01],\n",
       "       [8.71092081e-04],\n",
       "       [3.98214459e-02],\n",
       "       [9.99996126e-01],\n",
       "       [1.63912773e-06],\n",
       "       [1.28924847e-04],\n",
       "       [2.86310732e-01],\n",
       "       [9.93136168e-01],\n",
       "       [1.00000000e+00],\n",
       "       [2.04056501e-03],\n",
       "       [9.99999881e-01],\n",
       "       [5.66244125e-07],\n",
       "       [9.99999166e-01],\n",
       "       [1.00000000e+00],\n",
       "       [9.99999821e-01],\n",
       "       [2.29477882e-06],\n",
       "       [9.99985456e-01],\n",
       "       [1.96549296e-03],\n",
       "       [4.85777855e-06],\n",
       "       [1.00000000e+00],\n",
       "       [3.19275856e-02],\n",
       "       [2.08616257e-07],\n",
       "       [9.98850644e-01],\n",
       "       [9.98846769e-01],\n",
       "       [1.00000000e+00],\n",
       "       [9.99972343e-01],\n",
       "       [0.00000000e+00],\n",
       "       [9.99971986e-01],\n",
       "       [9.96464014e-01],\n",
       "       [9.99913096e-01],\n",
       "       [9.99925852e-01],\n",
       "       [9.93016124e-01],\n",
       "       [9.99769092e-01],\n",
       "       [0.00000000e+00],\n",
       "       [3.30591500e-02],\n",
       "       [9.99028802e-01],\n",
       "       [0.00000000e+00],\n",
       "       [9.95159745e-01],\n",
       "       [9.99985516e-01],\n",
       "       [6.73308969e-03],\n",
       "       [1.55270100e-05],\n",
       "       [4.56854701e-03],\n",
       "       [1.90228224e-04],\n",
       "       [9.91344690e-01],\n",
       "       [1.00000000e+00],\n",
       "       [9.70065594e-05],\n",
       "       [4.39137518e-01],\n",
       "       [1.53405666e-02],\n",
       "       [9.94613051e-01],\n",
       "       [9.99956667e-01],\n",
       "       [1.43280923e-01],\n",
       "       [1.00000000e+00],\n",
       "       [3.07013094e-02],\n",
       "       [1.00000000e+00],\n",
       "       [9.99974251e-01],\n",
       "       [9.99999940e-01],\n",
       "       [8.88241529e-01],\n",
       "       [9.41482186e-03],\n",
       "       [4.39018011e-04],\n",
       "       [9.99999642e-01],\n",
       "       [9.99855101e-01],\n",
       "       [9.99999762e-01],\n",
       "       [0.00000000e+00],\n",
       "       [8.94069672e-08],\n",
       "       [0.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [9.50111508e-01],\n",
       "       [9.99558091e-01],\n",
       "       [9.99474168e-01],\n",
       "       [9.99603510e-01],\n",
       "       [1.75297260e-04],\n",
       "       [2.17556953e-06],\n",
       "       [4.16454673e-03],\n",
       "       [2.71201134e-06],\n",
       "       [1.00000000e+00],\n",
       "       [1.15015566e-01],\n",
       "       [1.82202518e-01],\n",
       "       [9.99629736e-01],\n",
       "       [9.99998569e-01],\n",
       "       [9.01248813e-01],\n",
       "       [1.00000000e+00],\n",
       "       [9.99997735e-01],\n",
       "       [2.98023224e-08],\n",
       "       [9.99985278e-01],\n",
       "       [9.99980211e-01],\n",
       "       [9.99661446e-01],\n",
       "       [2.63151526e-03],\n",
       "       [9.99998450e-01],\n",
       "       [9.99933720e-01],\n",
       "       [1.43603951e-01],\n",
       "       [2.84874439e-03],\n",
       "       [2.98023224e-07],\n",
       "       [9.99999762e-01],\n",
       "       [6.98536634e-04],\n",
       "       [4.47153151e-02],\n",
       "       [9.73181963e-01],\n",
       "       [9.62615013e-06],\n",
       "       [1.43051147e-06],\n",
       "       [9.99370575e-01],\n",
       "       [0.00000000e+00],\n",
       "       [9.99998212e-01],\n",
       "       [9.99367714e-01],\n",
       "       [1.00000000e+00],\n",
       "       [0.00000000e+00],\n",
       "       [1.23953819e-03],\n",
       "       [9.99446094e-01],\n",
       "       [9.46727872e-01],\n",
       "       [3.69548798e-06],\n",
       "       [9.99999166e-01],\n",
       "       [4.98798490e-03],\n",
       "       [7.23102808e-01],\n",
       "       [3.89814377e-05],\n",
       "       [1.00000000e+00],\n",
       "       [9.99884903e-01],\n",
       "       [9.97615337e-01],\n",
       "       [4.61935997e-06],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.06990337e-05],\n",
       "       [1.00000000e+00],\n",
       "       [9.99999285e-01],\n",
       "       [9.99888539e-01],\n",
       "       [9.99797225e-01],\n",
       "       [1.00000000e+00],\n",
       "       [9.99879718e-01],\n",
       "       [9.99995172e-01],\n",
       "       [1.00000000e+00],\n",
       "       [4.20027763e-01],\n",
       "       [9.99774218e-01],\n",
       "       [1.00000000e+00],\n",
       "       [0.00000000e+00],\n",
       "       [3.68440151e-03],\n",
       "       [9.17767167e-01],\n",
       "       [4.64558601e-04],\n",
       "       [9.99929667e-01],\n",
       "       [9.99987483e-01],\n",
       "       [9.99998331e-01],\n",
       "       [2.11834908e-04],\n",
       "       [2.08616257e-07],\n",
       "       [3.27825546e-07],\n",
       "       [9.99979615e-01],\n",
       "       [9.94334877e-01],\n",
       "       [1.00000000e+00],\n",
       "       [8.98540020e-05],\n",
       "       [0.00000000e+00],\n",
       "       [2.95362234e-01],\n",
       "       [1.00821257e-03],\n",
       "       [1.18911266e-05],\n",
       "       [9.15459871e-01],\n",
       "       [8.49180996e-01],\n",
       "       [2.87324190e-04],\n",
       "       [4.47034836e-06],\n",
       "       [1.51889741e-01],\n",
       "       [6.12050295e-04],\n",
       "       [1.96993351e-05],\n",
       "       [3.69548798e-06],\n",
       "       [1.00000000e+00],\n",
       "       [0.00000000e+00],\n",
       "       [4.60377336e-02],\n",
       "       [9.99959111e-01],\n",
       "       [1.91837549e-04],\n",
       "       [4.97698784e-06],\n",
       "       [9.99807656e-01],\n",
       "       [4.76837158e-06],\n",
       "       [0.00000000e+00],\n",
       "       [9.86265063e-01],\n",
       "       [9.98163581e-01],\n",
       "       [1.60932541e-06],\n",
       "       [9.99874353e-01],\n",
       "       [9.99968529e-01],\n",
       "       [6.49690628e-06],\n",
       "       [9.99999046e-01],\n",
       "       [6.49094582e-05],\n",
       "       [4.73762721e-01],\n",
       "       [9.99981046e-01],\n",
       "       [9.60452080e-01],\n",
       "       [1.34503841e-03],\n",
       "       [2.68220901e-07],\n",
       "       [9.99037087e-01],\n",
       "       [9.99256790e-01],\n",
       "       [9.99774694e-01],\n",
       "       [1.69436216e-01],\n",
       "       [1.00000000e+00],\n",
       "       [9.99039769e-01],\n",
       "       [1.00000000e+00],\n",
       "       [1.39057636e-04],\n",
       "       [9.98137891e-01],\n",
       "       [9.99997079e-01],\n",
       "       [1.08191907e-01],\n",
       "       [9.99999881e-01],\n",
       "       [9.99997497e-01],\n",
       "       [6.10613644e-01],\n",
       "       [9.98366237e-01],\n",
       "       [9.99866486e-01],\n",
       "       [9.99990642e-01],\n",
       "       [9.99870598e-01],\n",
       "       [9.21856642e-01],\n",
       "       [9.41130877e-01],\n",
       "       [2.60174274e-05],\n",
       "       [9.91723061e-01],\n",
       "       [9.99999523e-01],\n",
       "       [3.65537107e-02],\n",
       "       [0.00000000e+00],\n",
       "       [9.91357803e-01],\n",
       "       [9.91563201e-01],\n",
       "       [9.99997854e-01],\n",
       "       [1.00135803e-05],\n",
       "       [8.41319561e-04],\n",
       "       [3.27825546e-07],\n",
       "       [0.00000000e+00],\n",
       "       [3.20929289e-03],\n",
       "       [3.05771828e-05],\n",
       "       [1.00000000e+00],\n",
       "       [0.00000000e+00],\n",
       "       [0.00000000e+00],\n",
       "       [9.00894403e-04],\n",
       "       [4.60743904e-04],\n",
       "       [0.00000000e+00],\n",
       "       [0.00000000e+00],\n",
       "       [9.73170042e-01],\n",
       "       [1.00000000e+00],\n",
       "       [1.29282475e-04],\n",
       "       [1.00000000e+00],\n",
       "       [9.99984264e-01],\n",
       "       [9.99807179e-01],\n",
       "       [4.09273207e-02],\n",
       "       [9.64016914e-01],\n",
       "       [9.90057409e-01],\n",
       "       [9.99999940e-01],\n",
       "       [2.75108218e-03],\n",
       "       [2.21818686e-03],\n",
       "       [9.99997079e-01],\n",
       "       [9.80317593e-04],\n",
       "       [0.00000000e+00],\n",
       "       [2.32458115e-05],\n",
       "       [8.94665718e-05],\n",
       "       [2.19637156e-03],\n",
       "       [9.99999881e-01],\n",
       "       [5.37931919e-05],\n",
       "       [9.98038352e-01],\n",
       "       [0.00000000e+00],\n",
       "       [9.96961951e-01],\n",
       "       [9.99750733e-01],\n",
       "       [1.89527869e-03],\n",
       "       [8.63137364e-01],\n",
       "       [0.00000000e+00],\n",
       "       [0.00000000e+00],\n",
       "       [1.14592910e-03],\n",
       "       [8.64267349e-07],\n",
       "       [9.97309685e-01],\n",
       "       [9.99997735e-01],\n",
       "       [9.73847113e-04],\n",
       "       [0.00000000e+00],\n",
       "       [3.39057714e-01]], dtype=float32)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds1 = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Data must be 1-dimensional",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-161-325f7378533d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcrosstab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreds1\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mrownames\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Actual'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcolnames\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Predicted'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmargins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\pivot.py\u001b[0m in \u001b[0;36mcrosstab\u001b[1;34m(index, columns, values, rownames, colnames, aggfunc, margins, margins_name, dropna, normalize)\u001b[0m\n\u001b[0;32m    509\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcommon_idx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    512\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mvalues\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m         \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'__dummy__'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    390\u001b[0m                                  dtype=dtype, copy=copy)\n\u001b[0;32m    391\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 392\u001b[1;33m             \u001b[0mmgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    393\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    394\u001b[0m             \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36minit_dict\u001b[1;34m(data, index, columns, dtype)\u001b[0m\n\u001b[0;32m    210\u001b[0m         \u001b[0marrays\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkeys\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 212\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    213\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, arr_names, index, columns, dtype)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[1;31m# don't force copy because getting jammed in an ndarray anyway\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m     \u001b[0marrays\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_homogenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[1;31m# from BlockManager perspective\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36m_homogenize\u001b[1;34m(data, index, dtype)\u001b[0m\n\u001b[0;32m    275\u001b[0m                 \u001b[0mval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfast_multiget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    276\u001b[0m             val = sanitize_array(val, index, dtype=dtype, copy=False,\n\u001b[1;32m--> 277\u001b[1;33m                                  raise_cast_failure=False)\n\u001b[0m\u001b[0;32m    278\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    279\u001b[0m         \u001b[0mhomogenized\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36msanitize_array\u001b[1;34m(data, index, dtype, copy, raise_cast_failure)\u001b[0m\n\u001b[0;32m    656\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0msubarr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    657\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 658\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Data must be 1-dimensional'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    659\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    660\u001b[0m             \u001b[0msubarr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray_tuplesafe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mException\u001b[0m: Data must be 1-dimensional"
     ]
    }
   ],
   "source": [
    "pd.crosstab(y_test, preds1 , rownames=['Actual'],colnames=['Predicted'], margins = True).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Data must be 1-dimensional",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-162-e11029c035fd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmy_conf_matrix1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmy_con\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmy_conf_matrix1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas_ml\\confusion_matrix\\cm.py\u001b[0m in \u001b[0;36m__new__\u001b[1;34m(cls, y_true, y_pred, *args, **kwargs)\u001b[0m\n\u001b[0;32m     22\u001b[0m                 \u001b[1;32mfrom\u001b[0m \u001b[0mpandas_ml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbcm\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBinaryConfusionMatrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mBinaryConfusionMatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mLabeledConfusionMatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas_ml\\confusion_matrix\\abstract.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, y_true, y_pred, labels, display_sum, backend, true_name, pred_name)\u001b[0m\n\u001b[0;32m     37\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_y_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpred_name\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_y_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpred_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[0;32m    260\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m                 data = sanitize_array(data, index, dtype, copy,\n\u001b[1;32m--> 262\u001b[1;33m                                       raise_cast_failure=True)\n\u001b[0m\u001b[0;32m    263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSingleBlockManager\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36msanitize_array\u001b[1;34m(data, index, dtype, copy, raise_cast_failure)\u001b[0m\n\u001b[0;32m    656\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0msubarr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    657\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 658\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Data must be 1-dimensional'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    659\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    660\u001b[0m             \u001b[0msubarr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray_tuplesafe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mException\u001b[0m: Data must be 1-dimensional"
     ]
    }
   ],
   "source": [
    "my_conf_matrix1 = my_con(y_test,model.predict(x_test)).ravel()\n",
    "my_conf_matrix1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of binary and continuous targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-163-a18ffb97b631>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreds1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'tn:'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'fp:'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'fn:'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'tp:'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[1;34m(y_true, y_pred, labels, sample_weight)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m     \"\"\"\n\u001b[1;32m--> 250\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    251\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"multiclass\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s is not supported\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[1;32m---> 81\u001b[1;33m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0m\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m     \u001b[1;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and continuous targets"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, preds1).ravel()\n",
    "print('tn:',tn, 'fp:',fp, 'fn:',fn, 'tp:',tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2 MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential([\n",
    "    # Flattening the input Layer into a vector because it is a matrix\n",
    "    Flatten(),\n",
    "    \n",
    "    Dense(128, activation = 'relu'),\n",
    "    \n",
    "    Dropout(0.20),\n",
    "    \n",
    "    #output layer with 1 neuron with the sigmoid function to counter for the 2 classes (1 or 0)\n",
    "    Dense(1, activation = 'sigmoid') # or tf.nn.softmax\n",
    "       \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compiler; using the adam optimizer and binary_crossentropy for binary classification\n",
    "model2.compile(optimizer='adam', loss = 'binary_crossentropy', metrics = ['accuracy'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "756/756 [==============================] - 0s 290us/sample - loss: 0.6865 - acc: 0.7765\n",
      "Epoch 2/20\n",
      "756/756 [==============================] - 0s 83us/sample - loss: 0.6810 - acc: 0.5780\n",
      "Epoch 3/20\n",
      "756/756 [==============================] - 0s 94us/sample - loss: 0.6757 - acc: 0.5675\n",
      "Epoch 4/20\n",
      "756/756 [==============================] - 0s 91us/sample - loss: 0.6712 - acc: 0.5648\n",
      "Epoch 5/20\n",
      "756/756 [==============================] - 0s 86us/sample - loss: 0.6680 - acc: 0.6217\n",
      "Epoch 6/20\n",
      "756/756 [==============================] - 0s 91us/sample - loss: 0.6608 - acc: 0.5741\n",
      "Epoch 7/20\n",
      "756/756 [==============================] - 0s 90us/sample - loss: 0.6544 - acc: 0.7077\n",
      "Epoch 8/20\n",
      "756/756 [==============================] - 0s 79us/sample - loss: 0.6452 - acc: 0.6614\n",
      "Epoch 9/20\n",
      "756/756 [==============================] - 0s 98us/sample - loss: 0.6375 - acc: 0.6376\n",
      "Epoch 10/20\n",
      "756/756 [==============================] - 0s 95us/sample - loss: 0.6273 - acc: 0.7513\n",
      "Epoch 11/20\n",
      "756/756 [==============================] - 0s 104us/sample - loss: 0.6156 - acc: 0.7884\n",
      "Epoch 12/20\n",
      "756/756 [==============================] - 0s 110us/sample - loss: 0.6074 - acc: 0.7817\n",
      "Epoch 13/20\n",
      "756/756 [==============================] - 0s 98us/sample - loss: 0.5962 - acc: 0.7659\n",
      "Epoch 14/20\n",
      "756/756 [==============================] - 0s 86us/sample - loss: 0.5845 - acc: 0.8585\n",
      "Epoch 15/20\n",
      "756/756 [==============================] - 0s 93us/sample - loss: 0.5737 - acc: 0.7712\n",
      "Epoch 16/20\n",
      "756/756 [==============================] - 0s 94us/sample - loss: 0.5605 - acc: 0.8545\n",
      "Epoch 17/20\n",
      "756/756 [==============================] - 0s 73us/sample - loss: 0.5525 - acc: 0.9021\n",
      "Epoch 18/20\n",
      "756/756 [==============================] - 0s 75us/sample - loss: 0.5376 - acc: 0.8108\n",
      "Epoch 19/20\n",
      "756/756 [==============================] - 0s 101us/sample - loss: 0.5270 - acc: 0.8981\n",
      "Epoch 20/20\n",
      "756/756 [==============================] - 0s 91us/sample - loss: 0.5146 - acc: 0.8307\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x25d16452358>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the data; 10 iterations\n",
    "model2.fit(x_train.values, y_train.values, epochs = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "324/324 [==============================] - 0s 176us/sample - loss: 0.5001 - acc: 0.9012\n",
      "\n",
      "Test Data Loss: 0.5001140420819506\n",
      "\n",
      "Test Data Accuracy: 90.123%\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the test dataset\n",
    "eval_array2 = model2.evaluate(x_test, y_test)\n",
    "\n",
    "print(\"\\nTest Data Loss: {}\".format(eval_array2[0]))\n",
    "print(\"\\nTest Data Accuracy: {:.5}%\".format(eval_array2[1] * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(y_pred_actual['y_actual'], y_pred_actual['y_predicted'], rownames=['Actual'],colnames=['Predicted'], margins = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_conf_matrix2 = my_con(y_pred_actual['y_actual'],y_pred_actual['y_predicted'])\n",
    "my_conf_matrix2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics, cross_validation, preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date           False\n",
       "High           False\n",
       "Low            False\n",
       "Open           False\n",
       "Close          False\n",
       "Volume         False\n",
       "Adj Close      False\n",
       "1day_Lag       False\n",
       "1day_target    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10 Fold Cross Validation Neural Net (Deep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, [1, 2, 3, 4, 5, 6]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = X.replace([np.inf, -np.inf], np.nan)\n",
    "#X.fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['1day_target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.replace([np.inf, -np.inf], np.nan)\n",
    "y.fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 23"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XEncoded = encoder.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "864/864 [==============================] - 2s 2ms/sample - loss: 0.0425 - acc: 0.9780\n",
      "216/216 [==============================] - 0s 1ms/sample - loss: 0.0207 - acc: 0.9954\n",
      "AUC (fold 1/10): 1.000000\n",
      "864/864 [==============================] - 0s 129us/sample - loss: 0.0319 - acc: 0.9884\n",
      "216/216 [==============================] - 0s 105us/sample - loss: 0.0219 - acc: 1.0000\n",
      "AUC (fold 2/10): 1.000000\n",
      "864/864 [==============================] - 0s 107us/sample - loss: 0.0242 - acc: 0.9907\n",
      "216/216 [==============================] - 0s 68us/sample - loss: 0.0176 - acc: 1.0000\n",
      "AUC (fold 3/10): 1.000000\n",
      "864/864 [==============================] - 0s 113us/sample - loss: 0.0272 - acc: 0.9907\n",
      "216/216 [==============================] - 0s 0s/sample - loss: 0.0187 - acc: 0.9954\n",
      "AUC (fold 4/10): 1.000000\n",
      "864/864 [==============================] - 0s 122us/sample - loss: 0.0249 - acc: 0.9942\n",
      "216/216 [==============================] - 0s 79us/sample - loss: 0.0273 - acc: 0.9907\n",
      "AUC (fold 5/10): 1.000000\n",
      "864/864 [==============================] - 0s 164us/sample - loss: 0.0257 - acc: 0.9931\n",
      "216/216 [==============================] - 0s 93us/sample - loss: 0.0171 - acc: 1.0000\n",
      "AUC (fold 6/10): 1.000000\n",
      "864/864 [==============================] - 0s 134us/sample - loss: 0.0275 - acc: 0.9896\n",
      "216/216 [==============================] - 0s 51us/sample - loss: 0.0260 - acc: 0.9861\n",
      "AUC (fold 7/10): 1.000000\n",
      "864/864 [==============================] - 0s 177us/sample - loss: 0.0357 - acc: 0.9861\n",
      "216/216 [==============================] - 0s 75us/sample - loss: 0.0119 - acc: 0.9954\n",
      "AUC (fold 8/10): 1.000000\n",
      "864/864 [==============================] - 0s 154us/sample - loss: 0.0283 - acc: 0.9884\n",
      "216/216 [==============================] - 0s 163us/sample - loss: 0.0216 - acc: 0.9954\n",
      "AUC (fold 9/10): 1.000000\n",
      "864/864 [==============================] - 0s 165us/sample - loss: 0.0270 - acc: 0.9907\n",
      "216/216 [==============================] - 0s 78us/sample - loss: 0.0184 - acc: 0.9907\n",
      "AUC (fold 10/10): 1.000000\n",
      "Mean AUC: 1.000000\n",
      "[99.53703880310059, 100.0, 100.0, 99.53703880310059, 99.0740716457367, 100.0, 98.61111044883728, 99.53703880310059, 99.53703880310059, 99.0740716457367]\n"
     ]
    }
   ],
   "source": [
    "axx = []\n",
    "mean_auc = 0.0\n",
    "n = 10  # repeat the CV procedure 10 times to get more precise results\n",
    "for i in range(n):\n",
    "    # for each iteration, randomly hold out 20% of the data as CV set\n",
    "    X_train, X_cv, y_train, y_cv = cross_validation.train_test_split(frame['x_features'], frame['y_target'], test_size=.20, random_state=i*SEED)\n",
    "\n",
    "    # train model and make predictions\n",
    "    model.fit(X_train, y_train) \n",
    "    preds = model.predict_proba(X_cv)\n",
    "    evals = model.evaluate(X_cv, y_cv)\n",
    "    axx.append(evals[1] * 100)\n",
    "\n",
    "    # compute AUC metric for this CV fold\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_cv, preds)\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    print(\"AUC (fold %d/%d): %f\"%(i + 1, n, roc_auc))\n",
    "    mean_auc += roc_auc\n",
    "\n",
    "print(\"Mean AUC: %f\"%(mean_auc/n))\n",
    "print(axx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "864/864 [==============================] - 0s 91us/sample - loss: 0.1160 - acc: 0.9815\n",
      "216/216 [==============================] - 0s 65us/sample - loss: 0.0979 - acc: 0.9861\n",
      "AUC (fold 1/10): 1.000000\n",
      "864/864 [==============================] - 0s 139us/sample - loss: 0.1137 - acc: 0.9792\n",
      "216/216 [==============================] - 0s 125us/sample - loss: 0.1005 - acc: 0.9954\n",
      "AUC (fold 2/10): 1.000000\n",
      "864/864 [==============================] - 0s 96us/sample - loss: 0.1110 - acc: 0.9850\n",
      "216/216 [==============================] - 0s 74us/sample - loss: 0.0981 - acc: 0.9815\n",
      "AUC (fold 3/10): 1.000000\n",
      "864/864 [==============================] - 0s 100us/sample - loss: 0.1140 - acc: 0.9838\n",
      "216/216 [==============================] - 0s 65us/sample - loss: 0.0907 - acc: 0.9954\n",
      "AUC (fold 4/10): 1.000000\n",
      "864/864 [==============================] - 0s 85us/sample - loss: 0.1055 - acc: 0.9884\n",
      "216/216 [==============================] - 0s 42us/sample - loss: 0.1207 - acc: 0.9907\n",
      "AUC (fold 5/10): 1.000000\n",
      "864/864 [==============================] - 0s 49us/sample - loss: 0.1057 - acc: 0.9780\n",
      "216/216 [==============================] - 0s 162us/sample - loss: 0.1146 - acc: 0.9815\n",
      "AUC (fold 6/10): 1.000000\n",
      "864/864 [==============================] - 0s 73us/sample - loss: 0.1122 - acc: 0.9780\n",
      "216/216 [==============================] - 0s 116us/sample - loss: 0.1042 - acc: 0.9861\n",
      "AUC (fold 7/10): 1.000000\n",
      "864/864 [==============================] - 0s 100us/sample - loss: 0.1090 - acc: 0.9838\n",
      "216/216 [==============================] - 0s 93us/sample - loss: 0.0844 - acc: 1.0000\n",
      "AUC (fold 8/10): 1.000000\n",
      "864/864 [==============================] - 0s 128us/sample - loss: 0.1027 - acc: 0.9826\n",
      "216/216 [==============================] - 0s 51us/sample - loss: 0.1123 - acc: 0.9907\n",
      "AUC (fold 9/10): 1.000000\n",
      "864/864 [==============================] - 0s 97us/sample - loss: 0.1104 - acc: 0.9745\n",
      "216/216 [==============================] - 0s 46us/sample - loss: 0.1030 - acc: 1.0000\n",
      "AUC (fold 10/10): 1.000000\n",
      "Mean AUC: 1.000000\n",
      "[98.61111044883728, 99.53703880310059, 98.14814925193787, 99.53703880310059, 99.0740716457367, 98.14814925193787, 98.61111044883728, 100.0, 99.0740716457367, 100.0]\n"
     ]
    }
   ],
   "source": [
    "axx2 = []\n",
    "mean_auc = 0.0\n",
    "n = 10  # repeat the CV procedure 10 times to get more precise results\n",
    "for i in range(n):\n",
    "    # for each iteration, randomly hold out 20% of the data as CV set\n",
    "    X_train, X_cv, y_train, y_cv = cross_validation.train_test_split(frame['x_features'], frame['y_target'], test_size=.20, random_state=i*SEED)\n",
    "\n",
    "    # train model and make predictions\n",
    "    model2.fit(X_train, y_train) \n",
    "    preds = model2.predict_proba(X_cv)\n",
    "    evals = model2.evaluate(X_cv, y_cv)\n",
    "    axx2.append(evals[1] * 100)\n",
    "\n",
    "    # compute AUC metric for this CV fold\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_cv, preds)\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    print(\"AUC (fold %d/%d): %f\"%(i + 1, n, roc_auc))\n",
    "    mean_auc += roc_auc\n",
    "\n",
    "print(\"Mean AUC: %f\"%(mean_auc/n))\n",
    "print(axx2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf= LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10 fold cross Validation LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC (fold 1/10): 0.434228\n",
      "AUC (fold 2/10): 0.506330\n",
      "AUC (fold 3/10): 0.444734\n",
      "AUC (fold 4/10): 0.493248\n",
      "AUC (fold 5/10): 0.470126\n",
      "AUC (fold 6/10): 0.440634\n",
      "AUC (fold 7/10): 0.487676\n",
      "AUC (fold 8/10): 0.478879\n",
      "AUC (fold 9/10): 0.448831\n",
      "AUC (fold 10/10): 0.489153\n",
      "Mean AUC: 0.469384\n"
     ]
    }
   ],
   "source": [
    "axx3 = []\n",
    "mean_auc = 0.0\n",
    "n = 10  # repeat the CV procedure 10 times to get more precise results\n",
    "for i in range(n):\n",
    "    # for each iteration, randomly hold out 20% of the data as CV set\n",
    "    X_train, X_cv, y_train, y_cv = cross_validation.train_test_split(df[['Adj Close']], df['1day_target'], test_size=.20, random_state=i*SEED)\n",
    "\n",
    "    # train model and make predictions\n",
    "    clf.fit(X_train, y_train) \n",
    "    preds = clf.predict_proba(X_cv)[:, 1]\n",
    "\n",
    "    # compute AUC metric for this CV fold\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_cv, preds)\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    axx3.append(roc_auc)\n",
    "    print(\"AUC (fold %d/%d): %f\"%(i + 1, n, roc_auc))\n",
    "    mean_auc += roc_auc\n",
    "\n",
    "print(\"Mean AUC: %f\"%(mean_auc/n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
